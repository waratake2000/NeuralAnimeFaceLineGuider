{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m create_directory_if_not_exists(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/root/dataset/SD_generated_dataset_checked/not_selected_\u001b[39m\u001b[39m{\u001b[39;00mtarget_dataset\u001b[39m}\u001b[39;00m\u001b[39m/annotations\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m create_directory_if_not_exists(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/root/dataset/SD_generated_dataset_checked/not_selected_\u001b[39m\u001b[39m{\u001b[39;00mtarget_dataset\u001b[39m}\u001b[39;00m\u001b[39m/images\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(csv_path)\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterpolate\u001b[39;00m \u001b[39mimport\u001b[39;00m interp1d \u001b[39m# scipyのモジュールを使う\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m clear_output\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1676\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1678\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1679\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1680\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1681\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype_backend\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[39m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/parsers.pyx:557\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def create_directory_if_not_exists(directory_path):\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "        \n",
    "target_dataset = \"radiantLightV2_2\"\n",
    "\n",
    "csv_path = f\"/root/dataset/SD_generated_dataset/{target_dataset}/annotations/annotations.csv\"\n",
    "dataset_img_path = f\"/root/dataset/SD_generated_dataset/{target_dataset}/images\"\n",
    "\n",
    "\n",
    "\n",
    "annotation_save_path = f\"/root/dataset/SD_generated_dataset_checked/{target_dataset}/annotations\"\n",
    "save_image_dir = f\"/root/dataset/SD_generated_dataset_checked/{target_dataset}/images\"\n",
    "create_directory_if_not_exists(f\"/root/dataset/SD_generated_dataset_checked/{target_dataset}\")\n",
    "create_directory_if_not_exists(f\"/root/dataset/SD_generated_dataset_checked/{target_dataset}/annotations\")\n",
    "create_directory_if_not_exists(f\"/root/dataset/SD_generated_dataset_checked/{target_dataset}/images\")\n",
    "\n",
    "not_annotation_save_path = f\"/root/dataset/SD_generated_dataset_checked/not_selected_{target_dataset}/annotations\"\n",
    "not_save_image_dir = f\"/root/dataset/SD_generated_dataset_checked/not_selected_{target_dataset}/images\"\n",
    "create_directory_if_not_exists(f\"/root/dataset/SD_generated_dataset_checked/not_selected_{target_dataset}\")\n",
    "create_directory_if_not_exists(f\"/root/dataset/SD_generated_dataset_checked/not_selected_{target_dataset}/annotations\")\n",
    "create_directory_if_not_exists(f\"/root/dataset/SD_generated_dataset_checked/not_selected_{target_dataset}/images\")\n",
    "\n",
    "data = pd.read_csv(csv_path).values.tolist()\n",
    "\n",
    "from scipy.interpolate import interp1d # scipyのモジュールを使う\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def spline_interp(in_x, in_y):\n",
    "    out_x = np.linspace(np.min(in_x), np.max(in_x), np.size(in_x)*100) # もとのxの個数より多いxを用意\n",
    "    func_spline = interp1d(in_x, in_y, kind='cubic') # cubicは3次のスプライン曲線\n",
    "    out_y = func_spline(out_x) # func_splineはscipyオリジナルの型\n",
    "\n",
    "    return out_x, out_y\n",
    "\n",
    "count = 0\n",
    "for csv_row_num,image_landmark in enumerate(data):\n",
    "    count += 1\n",
    "    print(\"すべての枚数:\",len(data))\n",
    "    print(\"現在の枚数:\",count)\n",
    "    try:\n",
    "        fig, ax = plt.subplots(1)\n",
    "        ax.tick_params(labelbottom=False, labelleft=False, labelright=False, labeltop=False)\n",
    "        image_name = image_landmark[0]\n",
    "        x_coordinates = image_landmark[3::2]\n",
    "        y_coordinates = image_landmark[4::2]\n",
    "        x_np = np.array(x_coordinates)\n",
    "        y_np = np.array(y_coordinates)\n",
    "        img = Image.open(f\"{dataset_img_path}/{image_name}\")\n",
    "        img.show()\n",
    "        ax.imshow(img)\n",
    "        plt.plot(x_np, y_np, 'o',color='red',markersize=1) # 上右眉\n",
    "        plt.show()\n",
    "        # time.sleep(1)\n",
    "        \n",
    "        # キー入力でデータセットとして利用可能か判断する\n",
    "        key_input = input()\n",
    "        \n",
    "        if key_input == \" \":\n",
    "            # アノテーションデータの保存    \n",
    "            with open(f\"{annotation_save_path}/annotations.csv\",\"a\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(image_landmark)\n",
    "            img.save(f\"{save_image_dir}/{image_name}\")\n",
    "            \n",
    "            del data[csv_row_num]\n",
    "            with open(csv_path, 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerows(data)\n",
    "            \n",
    "            os.remove(f\"{dataset_img_path}/{image_name}\")\n",
    "            clear_output(True)\n",
    "            \n",
    "        else:\n",
    "            # アノテーションデータの保存    \n",
    "            with open(f\"{not_annotation_save_path}/annotations.csv\",\"a\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                \n",
    "                writer.writerow(image_landmark)\n",
    "            img.save(f\"{not_save_image_dir}/{image_name}\")\n",
    "            \n",
    "            del data[csv_row_num]\n",
    "            with open(csv_path, 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerows(data)\n",
    "            \n",
    "            os.remove(f\"{dataset_img_path}/{image_name}\")\n",
    "            print(\"使用されませんでした\")\n",
    "            clear_output(True)\n",
    "    except:\n",
    "        continue\n",
    "    clear_output(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def create_directory_if_not_exists(directory_path):\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "        \n",
    "target_dataset = \"radiantLightV2_1\"\n",
    "\n",
    "csv_path = f\"/root/dataset/SD_generated_dataset/{target_dataset}/annotations/annotations.csv\"\n",
    "dataset_img_path = f\"/root/dataset/SD_generated_dataset/{target_dataset}/images\"\n",
    "\n",
    "\n",
    "\n",
    "annotation_save_path = f\"/root/dataset/SD_generated_dataset_checked/{target_dataset}/annotations\"\n",
    "save_image_dir = f\"/root/dataset/SD_generated_dataset_checked/{target_dataset}/images\"\n",
    "create_directory_if_not_exists(f\"/root/dataset/SD_generated_dataset_checked/{target_dataset}\")\n",
    "create_directory_if_not_exists(f\"/root/dataset/SD_generated_dataset_checked/{target_dataset}/annotations\")\n",
    "create_directory_if_not_exists(f\"/root/dataset/SD_generated_dataset_checked/{target_dataset}/images\")\n",
    "\n",
    "not_annotation_save_path = f\"/root/dataset/SD_generated_dataset_checked/not_selected_{target_dataset}/annotations\"\n",
    "not_save_image_dir = f\"/root/dataset/SD_generated_dataset_checked/not_selected_{target_dataset}/images\"\n",
    "create_directory_if_not_exists(f\"/root/dataset/SD_generated_dataset_checked/not_selected_{target_dataset}\")\n",
    "create_directory_if_not_exists(f\"/root/dataset/SD_generated_dataset_checked/not_selected_{target_dataset}/annotations\")\n",
    "create_directory_if_not_exists(f\"/root/dataset/SD_generated_dataset_checked/not_selected_{target_dataset}/images\")\n",
    "\n",
    "data = pd.read_csv(csv_path).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
